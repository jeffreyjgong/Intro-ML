{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jeffreyjgong/Intro-ML/blob/main/01_exercise_binary_classification_perceptron.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Exercise 1: Training, Validation, and Testing a Perceptron**\n",
        "\n",
        "*CPSC 381/581: Machine Learning*\n",
        "\n",
        "*Yale University*\n",
        "\n",
        "*Instructor: Alex Wong*\n",
        "\n",
        "\n",
        "**Prerequisites**:\n",
        "\n",
        "1. Enable Google Colaboratory as an app on your Google Drive account\n",
        "\n",
        "2. Create a new Google Colab notebook, this will also create a \"Colab Notebooks\" directory under \"MyDrive\" i.e.\n",
        "```\n",
        "/content/drive/MyDrive/Colab Notebooks\n",
        "```\n",
        "\n",
        "3. Create the following directory structure in your Google Drive\n",
        "```\n",
        "/content/drive/MyDrive/Colab Notebooks/CPSC 381-581: Machine Learning/Exercises\n",
        "```\n",
        "\n",
        "4. Move the 01_exercise.ipynb into\n",
        "```\n",
        "/content/drive/MyDrive/Colab Notebooks/CPSC 381-581: Machine Learning/Exercises\n",
        "```\n",
        "so that its absolute path is\n",
        "```\n",
        "/content/drive/MyDrive/Colab Notebooks/CPSC 381-581: Machine Learning/Exercises/01_exercise.ipynb\n",
        "```\n",
        "\n",
        "In this exercise, we will introduce basic data handling using NumPy to create training, validation and testing splits. We will implement a training and validation loop for a Perceptron and test it on the testing split.\n",
        "\n",
        "\n",
        "**Submission**:\n",
        "\n",
        "1. Implement all TODOs in the code blocks below.\n",
        "\n",
        "2. Report your validation and testing scores.\n",
        "\n",
        "```\n",
        "Report validation and testing scores here. For example,\n",
        "\n",
        "Max training iterations: 1\n",
        "Training loss: 0.18681  Validation accuracy: 80.70%\n",
        "Max training iterations: 2\n",
        "Training loss: 0.61978  Validation accuracy: 43.86%\n",
        "Max training iterations: 3\n",
        "Training loss: 0.08791  Validation accuracy: 87.72%\n",
        "Max training iterations: 4\n",
        "Training loss: 0.08352  Validation accuracy: 91.23%\n",
        "\n",
        "Test accuracy: 87.72%\n",
        "\n",
        "```\n",
        "\n",
        "3. List any collaborators.\n",
        "\n",
        "```\n",
        "Collaborators: Doe, Jane (Please write names in <Last Name, First Name> format)\n",
        "\n",
        "Collaboration details: Discussed ... implementation details with Jane Doe.\n",
        "```"
      ],
      "metadata": {
        "id": "_0fsGaVMMpwG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import packages"
      ],
      "metadata": {
        "id": "wxeZsiCGC0J8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install scikit-learn==1.1"
      ],
      "metadata": {
        "id": "CzIMN8VNjUxV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uumvcyiQ-k21"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import sklearn.datasets as skdata\n",
        "from sklearn.linear_model import Perceptron\n",
        "import warnings\n",
        "\n",
        "warnings.filterwarnings(action='ignore')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Loading data"
      ],
      "metadata": {
        "id": "5ljMielQC7Lg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: Load breast cancer dataset\n",
        "# dictionary object keyed by data, target, target_names, feature_names, ...\n",
        "breast_cancer_data = skdata.load_breast_cancer()\n",
        "\n",
        "# TODO: Get data, target, target_names, and feature_names from the dataset\n",
        "x = None\n",
        "y = None\n",
        "target_names = None\n",
        "feature_names = None\n",
        "\n",
        "# TODO: Show the number of samples and features in the dataset\n",
        "print('Number of samples in dataset: {}'.format(None))\n",
        "print('Number of features in each sample: {}'.format(None))\n",
        "\n",
        "# TODO: Check to make sure that there are the same number of ground truth\n",
        "assert True, 'Number of sample and ground truth does not match!'"
      ],
      "metadata": {
        "id": "6wlWiioqDBkG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Accessing the features of the dataset"
      ],
      "metadata": {
        "id": "SgFKGRDagRNz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: Examine the dataset by showing the first two data points\n",
        "# Print each feature name and value in each line \"<name>: <value>\" followed by \"target: <name> (<value>)\"\n",
        "for sample_idx in None:\n",
        "\n",
        "    print('sample: {}'.format(sample_idx + 1))\n",
        "\n",
        "    for feature_value, feature_name in None:\n",
        "        print('{} : {}'.format(None, None))\n",
        "\n",
        "    target_name = None\n",
        "    print('target: {} ({}) \\n'.format(None, None))"
      ],
      "metadata": {
        "id": "d85Zv7nifE3e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creating the training, validation and testing splits"
      ],
      "metadata": {
        "id": "v01ndhtiEoWh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: Shuffle the dataset based on sample indices\n",
        "shuffled_indices = None\n",
        "\n",
        "# TODO: Choose the first 80% as training set, next 10% as validation and the rest as testing\n",
        "train_split_size = None\n",
        "val_split_size = None\n",
        "\n",
        "train_indices = None\n",
        "val_indices = None\n",
        "test_indices = None\n",
        "\n",
        "# TODO: Select the examples from x and y to construct our training, validation, testing sets\n",
        "x_train, y_train = None, None\n",
        "x_val, y_val = None, None\n",
        "x_test, y_test = None, None\n",
        "\n",
        "# TODO: Print the number of samples in training, validation and testing sets\n",
        "print('Number of samples in dataset: {}'.format(None))\n",
        "print('Number of training samples: {}'.format(None))\n",
        "print('Number of validation samples: {}'.format(None))\n",
        "print('Number of testing samples: {}'.format(None))"
      ],
      "metadata": {
        "id": "ZYV_5EGeEvKy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Implementing training and validation loop"
      ],
      "metadata": {
        "id": "Gcb2TArNKvf1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def mean_accuracy(predictions, ground_truths):\n",
        "    '''\n",
        "    Computes the mean accuracy between predictions and ground truths\n",
        "\n",
        "    Arg(s):\n",
        "        predictions : numpy[int64]\n",
        "            predictions (y_hat)\n",
        "        ground_truths : numpy[int64]\n",
        "            groundtruth labels (y)\n",
        "    Returns:\n",
        "        float : mean accuracy score\n",
        "    '''\n",
        "\n",
        "    # TODO: Implement mean accuracy\n",
        "    mean_accuracy = 0.0\n",
        "\n",
        "    return mean_accuracy"
      ],
      "metadata": {
        "id": "7FYhX9G7unRw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a list to store perceptron models\n",
        "models = []\n",
        "\n",
        "# Define a list of max iterations\n",
        "max_iterations = [1, 2, 3, 4]\n",
        "\n",
        "# Define a list to store training losses and validation accuracy scores\n",
        "losses_train = []\n",
        "mean_accuracies_val = []\n",
        "\n",
        "for max_iter in max_iterations:\n",
        "\n",
        "    '''\n",
        "    Training the perceptron model\n",
        "    '''\n",
        "    # TODO: Set up our Perceptron model\n",
        "    # max_iter is the maximum iterations through the data for training the perceptron\n",
        "    # penalty and alpha relates to regularization (which we havenâ€™t covered so ignore them)\n",
        "    model = None\n",
        "\n",
        "    # TODO: Train our perceptron model on the training set using fit function\n",
        "\n",
        "\n",
        "    # TODO: Score model into list of models\n",
        "\n",
        "\n",
        "    # TODO: Make predictions on the validation set using the predict function\n",
        "    y_hat_train = None\n",
        "\n",
        "    # TODO: Compute the loss on the training set\n",
        "    scores_train = None\n",
        "    loss_train = None\n",
        "\n",
        "    # TODO: Store the loss into our set of losses\n",
        "\n",
        "\n",
        "    '''\n",
        "    Validate our perceptron model on the validation set\n",
        "    '''\n",
        "    # TODO: Make predictions on the validation set using the predict function\n",
        "    y_hat_val = None\n",
        "\n",
        "    # TODO: Compute the accuracy on the validation set\n",
        "    accuracy_val = None\n",
        "    mean_accuracy_val = 0.0\n",
        "\n",
        "    # TODO: Store the score into\n",
        "\n",
        "\n",
        "    print('Max training iterations: {}'.format(max_iter))\n",
        "    print('Training loss: {:0.5f}  Validation accuracy: {:0.2f}%'.format(loss_train, 100 * mean_accuracy_val))\n",
        "\n",
        "# TODO: Choose the best model based on highest validation accuracy\n",
        "best_model_idx = None\n",
        "best_model = None"
      ],
      "metadata": {
        "id": "yB29ajtrK8sQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Testing our model"
      ],
      "metadata": {
        "id": "dSApmaTZtlp6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: Make predictions on the testing set using our best model\n",
        "y_hat_test = None\n",
        "\n",
        "# TODO: Compute the accuracy on the testing set\n",
        "accuracy_test = None\n",
        "mean_accuracy_test = 0.0\n",
        "\n",
        "print('Test accuracy: {:0.2f}%'.format(100 * mean_accuracy_test))"
      ],
      "metadata": {
        "id": "KsdZWwJMtlFS"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}